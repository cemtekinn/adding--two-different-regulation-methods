{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir önceki sorudaki Prensesi Iyileştir problemindeki yapay sinir ağınıza seçtiğiniz herhangi\n",
    "iki farklı regülarizasyon yöntemi ekleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Adım [10/79], Kayıp: 0.6427\n",
      "Epoch [1/10], Adım [20/79], Kayıp: 0.7137\n",
      "Epoch [1/10], Adım [30/79], Kayıp: 0.7715\n",
      "Epoch [1/10], Adım [40/79], Kayıp: 0.8365\n",
      "Epoch [1/10], Adım [50/79], Kayıp: 0.7104\n",
      "Epoch [1/10], Adım [60/79], Kayıp: 0.6516\n",
      "Epoch [1/10], Adım [70/79], Kayıp: 0.9435\n",
      "Epoch [2/10], Adım [10/79], Kayıp: 0.8959\n",
      "Epoch [2/10], Adım [20/79], Kayıp: 0.7243\n",
      "Epoch [2/10], Adım [30/79], Kayıp: 0.7476\n",
      "Epoch [2/10], Adım [40/79], Kayıp: 0.7381\n",
      "Epoch [2/10], Adım [50/79], Kayıp: 0.6861\n",
      "Epoch [2/10], Adım [60/79], Kayıp: 0.6590\n",
      "Epoch [2/10], Adım [70/79], Kayıp: 0.6903\n",
      "Epoch [3/10], Adım [10/79], Kayıp: 0.7659\n",
      "Epoch [3/10], Adım [20/79], Kayıp: 0.7703\n",
      "Epoch [3/10], Adım [30/79], Kayıp: 0.6281\n",
      "Epoch [3/10], Adım [40/79], Kayıp: 0.4447\n",
      "Epoch [3/10], Adım [50/79], Kayıp: 0.6785\n",
      "Epoch [3/10], Adım [60/79], Kayıp: 0.5312\n",
      "Epoch [3/10], Adım [70/79], Kayıp: 0.6354\n",
      "Epoch [4/10], Adım [10/79], Kayıp: 0.5705\n",
      "Epoch [4/10], Adım [20/79], Kayıp: 0.6875\n",
      "Epoch [4/10], Adım [30/79], Kayıp: 0.9109\n",
      "Epoch [4/10], Adım [40/79], Kayıp: 0.8644\n",
      "Epoch [4/10], Adım [50/79], Kayıp: 0.6107\n",
      "Epoch [4/10], Adım [60/79], Kayıp: 0.7781\n",
      "Epoch [4/10], Adım [70/79], Kayıp: 0.8123\n",
      "Epoch [5/10], Adım [10/79], Kayıp: 0.7709\n",
      "Epoch [5/10], Adım [20/79], Kayıp: 0.6780\n",
      "Epoch [5/10], Adım [30/79], Kayıp: 0.6887\n",
      "Epoch [5/10], Adım [40/79], Kayıp: 0.6885\n",
      "Epoch [5/10], Adım [50/79], Kayıp: 0.7435\n",
      "Epoch [5/10], Adım [60/79], Kayıp: 0.7867\n",
      "Epoch [5/10], Adım [70/79], Kayıp: 0.6187\n",
      "Epoch [6/10], Adım [10/79], Kayıp: 0.5288\n",
      "Epoch [6/10], Adım [20/79], Kayıp: 0.6367\n",
      "Epoch [6/10], Adım [30/79], Kayıp: 0.6990\n",
      "Epoch [6/10], Adım [40/79], Kayıp: 0.5871\n",
      "Epoch [6/10], Adım [50/79], Kayıp: 0.6771\n",
      "Epoch [6/10], Adım [60/79], Kayıp: 0.8122\n",
      "Epoch [6/10], Adım [70/79], Kayıp: 0.8151\n",
      "Epoch [7/10], Adım [10/79], Kayıp: 0.4997\n",
      "Epoch [7/10], Adım [20/79], Kayıp: 0.7952\n",
      "Epoch [7/10], Adım [30/79], Kayıp: 0.5263\n",
      "Epoch [7/10], Adım [40/79], Kayıp: 0.6042\n",
      "Epoch [7/10], Adım [50/79], Kayıp: 0.8228\n",
      "Epoch [7/10], Adım [60/79], Kayıp: 0.8190\n",
      "Epoch [7/10], Adım [70/79], Kayıp: 0.5760\n",
      "Epoch [8/10], Adım [10/79], Kayıp: 0.8560\n",
      "Epoch [8/10], Adım [20/79], Kayıp: 0.9155\n",
      "Epoch [8/10], Adım [30/79], Kayıp: 0.7713\n",
      "Epoch [8/10], Adım [40/79], Kayıp: 0.7908\n",
      "Epoch [8/10], Adım [50/79], Kayıp: 0.7875\n",
      "Epoch [8/10], Adım [60/79], Kayıp: 0.7088\n",
      "Epoch [8/10], Adım [70/79], Kayıp: 0.5531\n",
      "Epoch [9/10], Adım [10/79], Kayıp: 0.6749\n",
      "Epoch [9/10], Adım [20/79], Kayıp: 0.5759\n",
      "Epoch [9/10], Adım [30/79], Kayıp: 0.5860\n",
      "Epoch [9/10], Adım [40/79], Kayıp: 0.5950\n",
      "Epoch [9/10], Adım [50/79], Kayıp: 0.6272\n",
      "Epoch [9/10], Adım [60/79], Kayıp: 0.5489\n",
      "Epoch [9/10], Adım [70/79], Kayıp: 0.6365\n",
      "Epoch [10/10], Adım [10/79], Kayıp: 0.5804\n",
      "Epoch [10/10], Adım [20/79], Kayıp: 0.5515\n",
      "Epoch [10/10], Adım [30/79], Kayıp: 0.6810\n",
      "Epoch [10/10], Adım [40/79], Kayıp: 0.6583\n",
      "Epoch [10/10], Adım [50/79], Kayıp: 0.5282\n",
      "Epoch [10/10], Adım [60/79], Kayıp: 0.8276\n",
      "Epoch [10/10], Adım [70/79], Kayıp: 0.5356\n",
      "Modelin test verilerindeki doğruluğu: % 65.28497409326425 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Verileri yükleme\n",
    "train_data = pd.read_csv('cure_the_princess_train.csv')\n",
    "test_data = pd.read_csv('cure_the_princess_test.csv')\n",
    "val_data = pd.read_csv('cure_the_princess_validation.csv')\n",
    "\n",
    "train_inputs = np.array(train_data.iloc[:, :-1])\n",
    "train_targets = np.array(train_data.iloc[:, -1])\n",
    "train_dataset = TensorDataset(torch.Tensor(train_inputs), torch.Tensor(train_targets))\n",
    "\n",
    "test_inputs = np.array(test_data.iloc[:, :-1])\n",
    "test_targets = np.array(test_data.iloc[:, -1])\n",
    "test_dataset = TensorDataset(torch.Tensor(test_inputs), torch.Tensor(test_targets))\n",
    "\n",
    "val_inputs = np.array(val_data.iloc[:, :-1])\n",
    "val_targets = np.array(val_data.iloc[:, -1])\n",
    "val_dataset = TensorDataset(torch.Tensor(val_inputs), torch.Tensor(val_targets))\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model tanımlama\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.sigmoid(self.fc3(out))\n",
    "        return out\n",
    "\n",
    "# Model eğitimi\n",
    "input_dim = 13 # özellik sayısı\n",
    "hidden_dim1 = 100\n",
    "hidden_dim2 = 50\n",
    "output_dim = 1\n",
    "model = MLP(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        \n",
    "        # L2 düzenlileştirme\n",
    "        l2_reg = None\n",
    "        for param in model.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = param.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + param.norm(2)\n",
    "        \n",
    "        loss += 0.001 * l2_reg\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Adım [{}/{}], Kayıp: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n",
    "            \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets.unsqueeze(1)).sum().item()\n",
    "\n",
    "print('Modelin test verilerindeki doğruluğu: % {} '.format(100 * correct / total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada, dropout katmanı ve p=0.2 ile belirtilen dropout oranı eklenmiştir. Ayrıca, weight_decay=0.01 ile belirtilen L2 düzenlileştirme parametresi de optimizasyon parametrelerine eklenmiştir. L2 düzenlileştirme, tüm ağırlıkların karesinin toplamının bir çarpanı ile kayıp fonksiyonuna eklenerek uygulanır."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout ve L2 düzenlileştirme yöntemlerini kullanmamın nedeni overfitting'i önlemek ve modelin genelleme performansını arttırmaktır.\n",
    "\n",
    "Dropout, her eğitim adımında rastgele seçilen birimleri atarak ağın öğrenme kapasitesini azaltır ve overfitting'i önler. Bu nedenle, dropout katmanı ekleyerek modelin daha iyi performans göstermesini sağlayabiliriz.\n",
    "\n",
    "L2 düzenlileştirme, ağırlıkların büyüklüklerini sınırlayarak aşırı öğrenmeyi azaltır. Bu nedenle, L2 düzenlileştirme parametresini ekleyerek modelin daha iyi genelleme performansı elde etmesini sağlayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kaybı: 0.6178\n",
      "Doğruluk: 0.6490\n",
      "F1 puanı: 0.6530\n",
      "Hassasiyet: 0.6489\n",
      "Geri çağırma: 0.6572\n",
      "Başarı Yüzdesi: 65.2011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Early stopping ile en iyi modeli seçme\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Doğrulama setindeki performansı hesaplama\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets.unsqueeze(1)).item()\n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        # En iyi modeli kaydetme\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = MLP(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    # Early stopping kontrolü\n",
    "    if epoch > 0 and val_loss > prev_val_loss:\n",
    "        break\n",
    "    prev_val_loss = val_loss\n",
    "\n",
    "# Test setinde performansı hesaplama\n",
    "test_loss = 0\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        outputs = best_model(inputs)\n",
    "        test_loss += criterion(outputs, targets.unsqueeze(1)).item()\n",
    "        preds = (outputs > 0.5).float()\n",
    "        test_preds.extend(preds.squeeze().tolist())\n",
    "        test_targets.extend(targets.tolist())\n",
    "test_loss /= len(test_dataloader)\n",
    "\n",
    "# Performans ölçütlerini hesaplama\n",
    "accuracy = accuracy_score(test_targets, test_preds)\n",
    "f1 = f1_score(test_targets, test_preds)\n",
    "precision = precision_score(test_targets, test_preds)\n",
    "recall = recall_score(test_targets, test_preds)\n",
    "success_rate = (accuracy + f1 + precision + recall) / 4 * 100\n",
    "\n",
    "print('Test kaybı: {:.4f}'.format(test_loss))\n",
    "print('Doğruluk: {:.4f}'.format(accuracy))\n",
    "print('F1 puanı: {:.4f}'.format(f1))\n",
    "print('Hassasiyet: {:.4f}'.format(precision))\n",
    "print('Geri çağırma: {:.4f}'.format(recall))\n",
    "print('Başarı Yüzdesi: {:.4f}'.format(success_rate))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
